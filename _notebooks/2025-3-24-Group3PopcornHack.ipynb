{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Group 2 Homework\n",
    "description: How do technological innovations impact society in both positive and negative ways?\n",
    "comments: true\n",
    "sticky_rank: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Popcorn Hack 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When emojis first came out, they only had yellow or light-skinned options. It wasn’t until later that darker skin tones were added.\n",
    "\n",
    "Who is Affected?\n",
    "People with darker skin who didn’t feel represented in emoji options.\n",
    "\n",
    "Potential Cause of This Bias\n",
    "The original designers may not have considered diversity and mainly based emojis on light-skinned characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Popcorn Hack 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One time, I was using voice-to-text on my phone to write a message while walking, but it kept misinterpreting my words—especially slang and names that weren’t \"standard.\" It was frustrating because I had to constantly stop and fix the errors, which defeated the purpose of using the feature hands-free. It made me feel overlooked, like the system wasn’t made for how I naturally speak. One way this technology could be more inclusive is by allowing users to “train” the software on their unique voice patterns and vocabulary over time, including dialects, accents, and slang, so it better reflects how diverse people actually communicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Popcorn Hack 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias could sneak into a fitness tracking app if the recommendations and performance evaluations are based on a narrow set of user data—like only healthy, young, able-bodied individuals. For example, if the app suggests daily step goals or calorie burn targets without considering a user’s age, mobility, chronic health conditions, or disability, it could unfairly label someone as underperforming or unhealthy. To make the app more fair and inclusive, it could start with an onboarding questionnaire that asks about physical limitations, goals, and health conditions. Then, it could offer customizable plans and redefine “progress” based on individual growth rather than generic standards. Including voice commands, screen reader compatibility, and gentle mental health check-ins would also help make the app more accessible to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework Hack 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One digital platform I use regularly is YouTube. I’ve noticed that the recommendation system often shows me similar types of content repeatedly—usually based on videos I’ve already watched or what’s trending globally. This creates a kind of \"filter bubble\" and doesn't expose me to diverse perspectives, creators, or interests outside of what the algorithm assumes I like. It also tends to favor content from larger creators over smaller or marginalized voices, which might make it harder for underrepresented groups to be discovered.\n",
    "\n",
    "This bias likely comes from how the recommendation algorithm is designed—it prioritizes watch time and engagement, which reinforces popular content and overlooks less mainstream creators. Additionally, if the training data is skewed toward certain demographics, the algorithm might unintentionally favor content that appeals to those groups.\n",
    "\n",
    "To make YouTube more inclusive, developers could add a “diversify my feed” option that intentionally recommends content from smaller creators, different regions, or a broader range of identities. They could also be more transparent about how the algorithm works and allow users to manually adjust the types of recommendations they want to see."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
